{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "agreed-korean",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (fc1): Linear(in_features=2, out_features=1, bias=False)\n",
      ")\n",
      "[Parameter containing:\n",
      "tensor([[0.0955, 0.4093]], requires_grad=True)]\n",
      "Epoch 0 - Batch 0 - Loss: 26.45721435546875\n",
      "Epoch 0 - Batch 1 - Loss: 80.30048370361328\n",
      "Epoch 1 - Batch 0 - Loss: 6.587774753570557\n",
      "Epoch 1 - Batch 1 - Loss: 148.34315490722656\n",
      "Epoch 2 - Batch 0 - Loss: 4.156954288482666\n",
      "Epoch 2 - Batch 1 - Loss: 107.85940551757812\n",
      "Epoch 3 - Batch 0 - Loss: 1.6441327333450317\n",
      "Epoch 3 - Batch 1 - Loss: 66.04778289794922\n",
      "Epoch 4 - Batch 0 - Loss: 1.599199652671814\n",
      "Epoch 4 - Batch 1 - Loss: 34.365840911865234\n",
      "Epoch 5 - Batch 0 - Loss: 0.9234740138053894\n",
      "Epoch 5 - Batch 1 - Loss: 19.675949096679688\n",
      "Epoch 6 - Batch 0 - Loss: 0.9163654446601868\n",
      "Epoch 6 - Batch 1 - Loss: 10.529974937438965\n",
      "Epoch 7 - Batch 0 - Loss: 0.6426243782043457\n",
      "Epoch 7 - Batch 1 - Loss: 6.902654647827148\n",
      "Epoch 8 - Batch 0 - Loss: 0.6023311614990234\n",
      "Epoch 8 - Batch 1 - Loss: 4.361929893493652\n",
      "Epoch 9 - Batch 0 - Loss: 0.4635615646839142\n",
      "Epoch 9 - Batch 1 - Loss: 3.3535501956939697\n",
      "Epoch 10 - Batch 0 - Loss: 0.4156806170940399\n",
      "Epoch 10 - Batch 1 - Loss: 2.475087881088257\n",
      "Epoch 11 - Batch 0 - Loss: 0.33484792709350586\n",
      "Epoch 11 - Batch 1 - Loss: 2.0583250522613525\n",
      "Epoch 12 - Batch 0 - Loss: 0.29236868023872375\n",
      "Epoch 12 - Batch 1 - Loss: 1.6454647779464722\n",
      "Epoch 13 - Batch 0 - Loss: 0.24100787937641144\n",
      "Epoch 13 - Batch 1 - Loss: 1.3971680402755737\n",
      "Epoch 14 - Batch 0 - Loss: 0.20731468498706818\n",
      "Epoch 14 - Batch 1 - Loss: 1.1537669897079468\n",
      "Epoch 15 - Batch 0 - Loss: 0.17294009029865265\n",
      "Epoch 15 - Batch 1 - Loss: 0.9815133213996887\n",
      "Epoch 16 - Batch 0 - Loss: 0.14755699038505554\n",
      "Epoch 16 - Batch 1 - Loss: 0.8210498690605164\n",
      "Epoch 17 - Batch 0 - Loss: 0.12385772913694382\n",
      "Epoch 17 - Batch 1 - Loss: 0.6971656680107117\n",
      "Epoch 18 - Batch 0 - Loss: 0.10521694272756577\n",
      "Epoch 18 - Batch 1 - Loss: 0.5863767862319946\n",
      "Epoch 19 - Batch 0 - Loss: 0.0886075496673584\n",
      "Epoch 19 - Batch 1 - Loss: 0.49699798226356506\n",
      "when x = tensor([1.0000, 2.1000]), y = tensor([3.1862], grad_fn=<SqueezeBackward4>)\n",
      "when x = tensor([2.0000, 3.5000]), y = tensor([6.1684], grad_fn=<SqueezeBackward4>)\n",
      "when x = tensor([3., 3.]), y = tensor([8.5972], grad_fn=<SqueezeBackward4>)\n",
      "when x = tensor([4.0000, 2.1000]), y = tensor([10.9094], grad_fn=<SqueezeBackward4>)\n",
      "when x = tensor([5.0000, 7.2000]), y = tensor([14.9695], grad_fn=<SqueezeBackward4>)\n",
      "when x = tensor([ 6.0000, 10.1000]), y = tensor([18.3888], grad_fn=<SqueezeBackward4>)\n"
     ]
    }
   ],
   "source": [
    "### Training with manually updating W with \"Backward\" ###\n",
    "\n",
    "import torch\n",
    "#from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "data = [(1.0,2.1,3.0), (2.0, 3.5, 6.0), (3.0, 3.0, 9.0), (4.0, 2.1, 12.0), (5.0, 7.2, 15.0), (6.0, 10.1, 18.0)]\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(2,1,bias=False)\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        return x\n",
    "\n",
    "net = Net()\n",
    "\n",
    "print(net)\n",
    "print(list(net.parameters()))\n",
    "\n",
    "#input = torch.randn(1)\n",
    "#out = net(input)\n",
    "\n",
    "#def criterion(out, label):\n",
    "#    return (label - out)**2\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.01, momentum=0.5)\n",
    "#optimizer = optim.Adam(net.parameters(), lr=0.005)\n",
    "\n",
    "for epoch in range(20):\n",
    "    for i in range(0, len(data), 3):\n",
    "        batch_data = data[i:i+3]\n",
    "        X_batch = torch.FloatTensor([[x1,x2,] for x1, x2, _ in batch_data])\n",
    "        Y_batch = torch.FloatTensor([[label] for _, _, label in batch_data])\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(X_batch)\n",
    "        loss = criterion(outputs, Y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # print(\"Epoch {} - loss: {}\".format(epoch, loss))\n",
    "        print(f\"Epoch {epoch} - Batch {i//3} - Loss: {loss.item()}\")\n",
    "for i, current_data in enumerate(data):\n",
    "    X = torch.FloatTensor([current_data[0], current_data[1]])\n",
    "    Y = torch.FloatTensor([current_data[2]])\n",
    "    out = net(X)\n",
    "    print(\"when x = {}, y = {}\".format(X, out))\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
